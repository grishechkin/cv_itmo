{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if DEVICE == 'cpu':\n",
    "    import multiprocessing\n",
    "    torch.set_num_threads(multiprocessing.cpu_count() or 4)\n",
    "print('CUDA:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "class CarColorDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "def collect_dataset(data_dir='data', min_samples=50):\n",
    "    data_dir = Path(data_dir)\n",
    "    all_images = list(data_dir.rglob('*.jpg')) + list(data_dir.rglob('*.jpeg'))\n",
    "    color_to_images = {}\n",
    "    for img_path in all_images:\n",
    "        filename = img_path.name\n",
    "        if '$$' in filename:\n",
    "            parts = filename.split('$$')\n",
    "            if len(parts) >= 4:\n",
    "                color = parts[3].lower()\n",
    "                if color == 'grey': color = 'gray'\n",
    "                if color in ['unlisted', 'multicolour']: continue\n",
    "                if color not in color_to_images: color_to_images[color] = []\n",
    "                color_to_images[color].append(str(img_path))\n",
    "    color_to_images = {c: imgs for c, imgs in color_to_images.items() if len(imgs) >= min_samples}\n",
    "    valid_colors = set(color_to_images.keys())\n",
    "    class_names = sorted(valid_colors)\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "    image_paths, labels = [], []\n",
    "    for color, imgs in color_to_images.items():\n",
    "        if color in valid_colors:\n",
    "            image_paths.extend(imgs)\n",
    "            labels.extend([class_to_idx[color]] * len(imgs))\n",
    "    return image_paths, labels, class_names\n",
    "\n",
    "data_dir = 'data' if Path('data').exists() else 'confirmed_fronts'\n",
    "image_paths, labels, class_names = collect_dataset(data_dir, min_samples=600)\n",
    "num_classes = len(class_names)\n",
    "print('Classes:', num_classes, 'Imgs:', len(image_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ON_CPU = not torch.cuda.is_available()\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0\n",
    "print('CPU mode:', ON_CPU, '| img_size:', IMG_SIZE, '| batch:', BATCH_SIZE)\n",
    "\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    transforms.RandomGrayscale(p=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_ds = CarColorDataset(train_paths, train_labels, train_tf)\n",
    "val_ds = CarColorDataset(val_paths, val_labels, val_tf)\n",
    "test_ds = CarColorDataset(test_paths, test_labels, val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=not ON_CPU)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=not ON_CPU)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=not ON_CPU)\n",
    "print('Train:', len(train_paths), 'Val:', len(val_paths), 'Test:', len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch))\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    def _make_layer(self, in_ch, out_ch, blocks, stride):\n",
    "        layers = [BasicBlock(in_ch, out_ch, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_ch, out_ch))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "LOG_PATH = 'training.log'\n",
    "log_file = open(LOG_PATH, 'w', encoding='utf-8')\n",
    "def log(msg):\n",
    "    print(msg)\n",
    "    log_file.write(msg + '\\n')\n",
    "    log_file.flush()\n",
    "log(f'Started {datetime.datetime.now().isoformat()}')\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "LR = 0.001\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, lbl in loader:\n",
    "        images, lbl = images.to(device, non_blocking=True), lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, lbl)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (out.argmax(1) == lbl).sum().item()\n",
    "        total += lbl.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, gt = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, lbl in loader:\n",
    "            out = model(images.to(device))\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            gt.extend(lbl.numpy())\n",
    "    return f1_score(gt, preds, average='macro', zero_division=0)\n",
    "\n",
    "def train_model(model, name, epochs=NUM_EPOCHS, lr=LR):\n",
    "    model = model.to(DEVICE)\n",
    "    weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    weights = torch.FloatTensor(weights).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    best_f1 = 0.0\n",
    "    for ep in range(epochs):\n",
    "        loss, acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        f1_val = evaluate(model, val_loader, DEVICE)\n",
    "        f1_train = evaluate(model, train_loader, DEVICE)\n",
    "        scheduler.step()\n",
    "        if f1_val > best_f1:\n",
    "            best_f1 = f1_val\n",
    "            torch.save(model.state_dict(), f'{name}_best.pth')\n",
    "        log(f'{name} ep{ep+1}/{epochs} loss={loss:.3f} acc={acc:.3f} f1_train={f1_train:.3f} val_f1={f1_val:.3f}')\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom = ResNet(num_classes=num_classes)\n",
    "f1_custom = train_model(model_custom, 'custom_resnet')\n",
    "log('Custom ResNet best val F1: ' + str(f1_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def get_pretrained_resnet18(num_classes):\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model_resnet18 = get_pretrained_resnet18(num_classes)\n",
    "f1_resnet18 = train_model(model_resnet18, 'pretrained_resnet18', lr=1e-4)\n",
    "log('ResNet18 best val F1: ' + str(f1_resnet18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_mobilenetv2(num_classes):\n",
    "    m = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "    m.classifier[1] = nn.Linear(m.last_channel, num_classes)\n",
    "    return m\n",
    "\n",
    "model_mobilenet = get_pretrained_mobilenetv2(num_classes)\n",
    "f1_mobilenet = train_model(model_mobilenet, 'pretrained_mobilenetv2', lr=1e-4)\n",
    "log('MobileNetV2 best val F1: ' + str(f1_mobilenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_f1(model):\n",
    "    model.eval()\n",
    "    preds, gt = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, lbl in test_loader:\n",
    "            out = model(images.to(DEVICE))\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            gt.extend(lbl.numpy())\n",
    "    return f1_score(gt, preds, average='macro', zero_division=0)\n",
    "\n",
    "model_custom.load_state_dict(torch.load('custom_resnet_best.pth', map_location=DEVICE))\n",
    "model_resnet18.load_state_dict(torch.load('pretrained_resnet18_best.pth', map_location=DEVICE))\n",
    "model_mobilenet.load_state_dict(torch.load('pretrained_mobilenetv2_best.pth', map_location=DEVICE))\n",
    "\n",
    "t_custom = test_f1(model_custom)\n",
    "t_resnet18 = test_f1(model_resnet18)\n",
    "t_mobilenet = test_f1(model_mobilenet)\n",
    "\n",
    "log('Test F1:')\n",
    "log('  Custom ResNet: ' + str(round(t_custom, 4)))\n",
    "log('  ResNet18: ' + str(round(t_resnet18, 4)))\n",
    "log('  MobileNetV2: ' + str(round(t_mobilenet, 4)))\n",
    "best_name = 'Custom ResNet' if t_custom >= max(t_resnet18, t_mobilenet) else ('ResNet18' if t_resnet18 >= t_mobilenet else 'MobileNetV2')\n",
    "log('Best: ' + best_name + ' | F1>0.8: ' + str(max(t_custom, t_resnet18, t_mobilenet) > 0.8))\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def plot_log_metrics(logfile):\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    accs = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'ep(\\d+)/(\\d+) loss=([0-9.]+) acc=([0-9.]+) f1_train=([0-9.]+) val_f1=([0-9.]+)'\n",
    "    )\n",
    "    with open(logfile, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            match = pattern.search(line)\n",
    "            if match:\n",
    "                epoch = int(match.group(1))\n",
    "                loss = float(match.group(3))\n",
    "                acc = float(match.group(4))\n",
    "                train_f1 = float(match.group(5))\n",
    "                val_f1 = float(match.group(6))\n",
    "\n",
    "                epochs.append(epoch)\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "                train_f1s.append(train_f1)\n",
    "                val_f1s.append(val_f1)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses, label='Loss')\n",
    "    plt.plot(epochs, accs, label='Accuracy')\n",
    "    plt.plot(epochs, train_f1s, label='Train F1')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Train Loss, Accuracy, Train F1')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_f1s, label='Validation F1', color='purple')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.title('Validation F1')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_metrics('resnet18_logs.log')\n",
    "plot_log_metrics('resnet_custom_logs.log')\n",
    "plot_log_metrics('mobilenetv2_logs.log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
